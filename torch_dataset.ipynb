{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelnet40.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aJK7MT_qvGQv7nHcWuP9c15FSmYipcXZ",
      "authorship_tag": "ABX9TyNL201IgTjndLqFpfBiFQ4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangbxj1234/offset_pt_try/blob/main/torch_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def load_data(partition):\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "    for h5_name in glob.glob('/content/drive/MyDrive/PAConv-main/modelnet40_ply_hdf5_2048/ply_data_%s*.h5' % partition):\n",
        "        f = h5py.File(h5_name, mode='r')\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        f.close()\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "    return all_data, all_label\n",
        "\n",
        "\n",
        "def pc_normalize(pc):###用了\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc = pc - centroid\n",
        "    m = np.max(np.sqrt(np.sum(pc ** 2, axis=1)))\n",
        "    pc = pc / m\n",
        "    return pc\n",
        "\n",
        "\n",
        "def translate_pointcloud(pointcloud):####用了\n",
        "    xyz1 = np.random.uniform(low=2. / 3., high=3. / 2., size=[3])####从一个均匀分布[low,high)中随机采样， size: 输出样本数目为3\n",
        "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])###########从一个均匀分布[low,high)中随机采样， size: 输出样本数目为3\n",
        "\n",
        "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')#######数据增强\n",
        "    return translated_pointcloud\n",
        "\n",
        "\n",
        "def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):####没用\n",
        "    N, C = pointcloud.shape\n",
        "    pointcloud += np.clip(sigma * np.random.randn(N, C), -1 * clip, clip)\n",
        "    return pointcloud\n",
        "\n",
        "\n",
        "class ModelNet40(Dataset):\n",
        "    def __init__(self, num_points, partition='train', pt_norm=False):\n",
        "        self.data, self.label = load_data(partition)\n",
        "        self.num_points = num_points\n",
        "        self.partition = partition\n",
        "        self.pt_norm = pt_norm\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        pointcloud = self.data[item][:self.num_points]            #####就取了前1024个点，不出问题才怪\n",
        "        label = self.label[item]\n",
        "        if self.partition == 'train':\n",
        "            if self.pt_norm:\n",
        "                pointcloud = pc_normalize(pointcloud)\n",
        "            pointcloud = translate_pointcloud(pointcloud)\n",
        "            np.random.shuffle(pointcloud)  # shuffle the order of pts\n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]#########原始data是：9840，2048，3， 从2048中取了1024个点\n",
        "    "
      ],
      "metadata": {
        "id": "ltoDbtI86Kt_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set=ModelNet40(partition='train', num_points=1024, pt_norm=True)"
      ],
      "metadata": {
        "id": "4h4Pwq116BEg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set[9839][0].shape###########9840,1024,3(point cloud)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBW8r8tySg6G",
        "outputId": "e3afe1fc-6a5d-42b6-fd01-9e793915c975"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set[9839][1].shape############9840,1 (label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4Qh8nCjTuSQ",
        "outputId": "469cee8a-6fe5-47f0-9f1c-b2dcb2e508fe"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D3EKa8J6WsE",
        "outputId": "2de97171-fad5-4746-dbbd-50823ae3233e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9840"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}