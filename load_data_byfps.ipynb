{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_data_byfps.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KIsNgUwq3G3FdzS8464FBQp0QtsrFrwb",
      "authorship_tag": "ABX9TyNRg6pHFJeBLXrZnr9vWvyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangbxj1234/offset_pt_try/blob/main/load_data_byfps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def farthest_point_sample(xyz, npoint):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape#############9840, 2048, 3\n",
        "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)#(9840, 1024)\n",
        "    distance = torch.ones(B, N).to(device) * 1e10        ###########(9840, 2048)\n",
        "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)######low:0,high:2048,  (9840,1)\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device)########### arange: to generate (0,1,2,.....,2047)\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest##################[9840,1]\n",
        "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3) ######(9840,2048,3)\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1)##################(9840,2048)\n",
        "        distance = torch.min(distance, dist)###############NO LARGER THAN 1e10\n",
        "        farthest = torch.max(distance, -1)[1]############## 取最远距离的那个点 得到坐标\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S, [K]]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, [K], C]\n",
        "    \"\"\"\n",
        "    raw_size = idx.size()\n",
        "    idx = idx.reshape(raw_size[0], -1)\n",
        "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
        "    return res.reshape(*raw_size, -1)\n",
        "def load_data(partition):\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "    for h5_name in glob.glob('/content/drive/MyDrive/PAConv-main/modelnet40_ply_hdf5_2048/ply_data_%s*.h5' % partition):\n",
        "        f = h5py.File(h5_name, mode='r')\n",
        "        data = f['data'][:].astype('float32')\n",
        "        label = f['label'][:].astype('int64')\n",
        "        f.close()\n",
        " ######### \n",
        "        data = torch.Tensor(data) \n",
        "        print(data.shape)     \n",
        "        fps_idx_single = farthest_point_sample(data, 1024)\n",
        "        data_1 = index_points(data, fps_idx_single)########### 按照index 返回 3维点。\n",
        "        data=data_1.data.numpy()\n",
        "        all_data.append(data)\n",
        " #########\n",
        "        all_label.append(label)\n",
        "        #\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "    print('all_data.shape:',all_data.shape)\n",
        "    return all_data, all_label\n",
        "\n"
      ],
      "metadata": {
        "id": "gqk4UdyfIM2e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partition='train'\n",
        "d_1,l_1=load_data(partition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv6vL4VVNVo3",
        "outputId": "4dc16c3d-2224-4ba8-8e7b-e500262cfabd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1648, 2048, 3])\n",
            "torch.Size([2048, 2048, 3])\n",
            "torch.Size([2048, 2048, 3])\n",
            "torch.Size([2048, 2048, 3])\n",
            "torch.Size([2048, 2048, 3])\n",
            "all_data.shape: (9840, 1024, 3)\n"
          ]
        }
      ]
    }
  ]
}